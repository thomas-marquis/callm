{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb578c1-c9d7-4e84-af30-27ea840a58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151b7875-2c74-4937-9691-d03ad3b8a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_python.configuration import LlamaConfig\n",
    "from llama_python.model import LlamaForCausalLM, LlamaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a2aec1-c7b8-4e76-859c-e9cff5ed21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_content: dict = json.load(open(\"../resources/original_llama/config.json\", \"r\"))\n",
    "model_config = LlamaConfig(**config_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89aeca81-e3c9-4469-b575-d24238d0b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_rotary_factor 1.0\n",
      "inv_freq tensor([1.0000e+00, 6.6360e-01, 4.4037e-01, 2.9223e-01, 1.9392e-01, 1.2869e-01,\n",
      "        8.5397e-02, 5.6670e-02, 3.7606e-02, 2.4955e-02, 1.6560e-02, 1.0990e-02,\n",
      "        7.2927e-03, 4.8394e-03, 3.2114e-03, 2.1311e-03, 1.4142e-03, 9.3847e-04,\n",
      "        6.2277e-04, 4.1327e-04, 2.7425e-04, 1.8199e-04, 1.2077e-04, 8.0143e-05,\n",
      "        5.3183e-05, 3.5292e-05, 2.3420e-05, 1.5542e-05, 1.0313e-05, 6.8440e-06,\n",
      "        4.5417e-06, 3.0139e-06])\n",
      "inv_freq shape torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "model = LlamaForCausalLM(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab5c555-9efe-475c-a62b-41dbc272631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "import torch\n",
    "\n",
    "state_dict = load_file(\"../model2.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a678b3d-c281-4a7a-87dc-13d2e257d9c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "list(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f132fd30-6f28-41c8-bc78-ed674e123c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"lm_head.weight\" not in state_dict:\n",
    "    model.lm_head.weight = model.get_input_embeddings().weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9eb2b75-0d80-402b-8042-c9d643d38df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['lm_head.weight']\n",
      "Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "print(\"Missing keys:\", missing_keys)\n",
    "print(\"Unexpected keys:\", unexpected_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1f6cf6-2194-47c9-9fac-e29b940ab864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2933,    73,   283,  6634, 91443,  7930,   296,   378,   247,   263,\n",
       "             83]], dtype=torch.int32),\n",
       " torch.Size([1, 11]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = [2933, 73, 283, 6634, 91443, 7930, 296, 378, 247, 263, 83]\n",
    "token_ids = torch.Tensor(token_ids).type(torch.int32).reshape((1, -1))\n",
    "token_ids, token_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc663d8f-7f7c-4d28-a488-71dcbe325eb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39423af0-2a56-4ea3-91a2-491109821d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5403, -0.4161, -0.9900,  0.5403, -0.4161, -0.9900],\n",
       "        [ 0.5403, -0.4161, -0.9900,  0.5403, -0.4161, -0.9900],\n",
       "        [ 0.5403, -0.4161, -0.9900,  0.5403, -0.4161, -0.9900],\n",
       "        [ 0.5403, -0.4161, -0.9900,  0.5403, -0.4161, -0.9900],\n",
       "        [ 0.5403, -0.4161, -0.9900,  0.5403, -0.4161, -0.9900]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "torch.cat((A, A), dim=1).cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e30378f3-e7e0-490c-9bdb-69781e5cd068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'layer.weight': tensor([[1.0000e+00, 2.0000e+00, 3.0000e+00],\n",
      "        [1.0000e+01, 2.0000e+01, 3.0000e+01],\n",
      "        [1.0000e+02, 2.0000e+02, 3.0000e+02],\n",
      "        [1.0000e+03, 2.0000e+03, 3.0000e+03]])})\n",
      "torch.Size([2, 3])\n",
      "tensor([[6.0000e+00, 6.0000e+01, 6.0000e+02, 6.0000e+03],\n",
      "        [1.2000e+01, 1.2000e+02, 1.2000e+03, 1.2000e+04]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(in_features=3, out_features=4, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        res = self.layer(input)\n",
    "        return res\n",
    "\n",
    "\n",
    "model = Test()\n",
    "state = {\n",
    "    \"layer.weight\": Tensor([\n",
    "        [1, 2, 3],\n",
    "        [10, 20, 30],\n",
    "        [100, 200, 300],\n",
    "        [1000, 2000, 3000],\n",
    "    ])\n",
    "}\n",
    "model = Test()\n",
    "model.load_state_dict(state)\n",
    "print(model.state_dict())\n",
    "\n",
    "input_data = Tensor([\n",
    "    [1, 1, 1],\n",
    "    [2, 2, 2],\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "print(input_data.shape)\n",
    "with torch.no_grad():\n",
    "    res = model(input_data)\n",
    "    print(res, res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e4541fd-1434-41d0-98d8-823f821f43ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]),\n",
       " tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9]],\n",
       " \n",
       "         [[10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]],\n",
       " \n",
       "         [[30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39]],\n",
       " \n",
       "         [[40, 41, 42, 43, 44],\n",
       "          [45, 46, 47, 48, 49]],\n",
       " \n",
       "         [[50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]]]),\n",
       " tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [30, 31, 32, 33, 34],\n",
       "          [40, 41, 42, 43, 44],\n",
       "          [50, 51, 52, 53, 54]],\n",
       " \n",
       "         [[ 5,  6,  7,  8,  9],\n",
       "          [15, 16, 17, 18, 19],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [45, 46, 47, 48, 49],\n",
       "          [55, 56, 57, 58, 59]]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.arange(60).reshape((6, 10))\n",
    "#data = torch.broadcast_to(data, (6, 10))\n",
    "data, data.view((6, -1, 5)), data.view((6, -1, 5)).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72dcd701-6811-4f2e-b3a9-0c4a2613d7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   2.],\n",
       "         [  3.,   4.],\n",
       "         [  5.,   6.]],\n",
       "\n",
       "        [[ 10.,  20.],\n",
       "         [ 30.,  40.],\n",
       "         [ 50.,  60.]],\n",
       "\n",
       "        [[100., 200.],\n",
       "         [300., 400.],\n",
       "         [500., 600.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Tensor([\n",
    "    [1, 2, 3, 4, 5, 6],\n",
    "    [10, 20, 30, 40, 50, 60],\n",
    "    [100, 200, 300, 400, 500, 600],\n",
    "])\n",
    "hidden_shape = (3, -1, 2)\n",
    "data.view(hidden_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a190e95-fada-4997-adef-4d4f539fc67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(6) * 2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2ce3d87-8486-4899-bda4-946035e497b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 4, 6])\n",
      "torch.Size([0, 1, 4, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1, 4, 6))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_states torch.Size([1, 32, 11, 64])\n",
    "\n",
    "x = Tensor([\n",
    "    [\n",
    "        [\n",
    "            (torch.arange(6) * 1).tolist(),\n",
    "            (torch.arange(6) * 2).tolist(),\n",
    "            (torch.arange(6) * 3).tolist(),\n",
    "            (torch.arange(6) * 4).tolist(),\n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            (torch.arange(6) * 10).tolist(),\n",
    "            (torch.arange(6) * 20).tolist(),\n",
    "            (torch.arange(6) * 30).tolist(),\n",
    "            (torch.arange(6) * 40).tolist(),\n",
    "        ]\n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            (torch.arange(6) * 100).tolist(),\n",
    "            (torch.arange(6) * 200).tolist(),\n",
    "            (torch.arange(6) * 300).tolist(),\n",
    "            (torch.arange(6) * 400).tolist(),\n",
    "        ]\n",
    "        \n",
    "    ]\n",
    "])\n",
    "print(x.shape)\n",
    "y = x[...,  x.shape[-1]//2 :]\n",
    "#y = x[..., : x.shape[-1]//2]\n",
    "y = x[x.shape[-1]//2 :, ...]kkk\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef28150-8c14-40f3-a583-e4247d86f424",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25c2beb-d085-415d-8fb7-30a87cae424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== LlamaModel.forward =========\n",
      "input_ids shape= torch.Size([1, 11])\n",
      "output_attentions False\n",
      "output_hidden_states False\n",
      "use_cache True\n",
      "return_dict True\n",
      "not in training mode\n",
      "inputs_embeds torch.Size([1, 11, 2048])\n",
      "init dynamic cache\n",
      "init cache_position\n",
      "past_seen_tokens 0\n",
      "cache_position shape torch.Size([11])\n",
      "cache_position tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "unsequeeze position_ids...\n",
      "position_ids None\n",
      "after unsqueeze position_ids shape torch.Size([1, 11])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "======== _update_causal_mask =========\n",
      "attention implementation sdpa\n",
      "sdpa\n",
      ">>>>>>>> LlamaModel.forward\n",
      "======== LlamaRotaryEmbedding.forward =========\n",
      "rope_type llama3\n",
      "inv_freq shape torch.Size([32])\n",
      "inv_freq tensor([1.0000e+00, 6.6360e-01, 4.4037e-01, 2.9223e-01, 1.9392e-01, 1.2869e-01,\n",
      "        8.5397e-02, 5.6670e-02, 3.7606e-02, 2.4955e-02, 1.6560e-02, 1.0990e-02,\n",
      "        7.2927e-03, 4.8394e-03, 3.2114e-03, 1.2905e-03, 4.2956e-04, 9.7083e-05,\n",
      "        1.9462e-05, 1.2915e-05, 8.5703e-06, 5.6872e-06, 3.7741e-06, 2.5045e-06,\n",
      "        1.6620e-06, 1.1029e-06, 7.3187e-07, 4.8567e-07, 3.2229e-07, 2.1387e-07,\n",
      "        1.4193e-07, 9.4183e-08])\n",
      "position_ids shape torch.Size([1, 11])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "inv_freq_expanded shape torch.Size([1, 32, 1])\n",
      "inv_freq_expanded tensor([[[1.0000e+00],\n",
      "         [6.6360e-01],\n",
      "         [4.4037e-01],\n",
      "         [2.9223e-01],\n",
      "         [1.9392e-01],\n",
      "         [1.2869e-01],\n",
      "         [8.5397e-02],\n",
      "         [5.6670e-02],\n",
      "         [3.7606e-02],\n",
      "         [2.4955e-02],\n",
      "         [1.6560e-02],\n",
      "         [1.0990e-02],\n",
      "         [7.2927e-03],\n",
      "         [4.8394e-03],\n",
      "         [3.2114e-03],\n",
      "         [1.2905e-03],\n",
      "         [4.2956e-04],\n",
      "         [9.7083e-05],\n",
      "         [1.9462e-05],\n",
      "         [1.2915e-05],\n",
      "         [8.5703e-06],\n",
      "         [5.6872e-06],\n",
      "         [3.7741e-06],\n",
      "         [2.5045e-06],\n",
      "         [1.6620e-06],\n",
      "         [1.1029e-06],\n",
      "         [7.3187e-07],\n",
      "         [4.8567e-07],\n",
      "         [3.2229e-07],\n",
      "         [2.1387e-07],\n",
      "         [1.4193e-07],\n",
      "         [9.4183e-08]]])\n",
      "position_ids_expanded shape torch.Size([1, 1, 11])\n",
      "position_ids_expanded tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]])\n",
      ">>>>>>>> LlamaModel.forward\n",
      "======== LlamaDecoderLayer.forward[0] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[0]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[0] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[0]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[1] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[1]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[1] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[1]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[2] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[2]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[2] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[2]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[3] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[3]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[3] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[3]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[4] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[4]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[4] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[4]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[5] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[5]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[5] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[5]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[6] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[6]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[6] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[6]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[7] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[7]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[7] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[7]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[8] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[8]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[8] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[8]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[9] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[9]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[9] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[9]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[10] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[10]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[10] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[10]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[11] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[11]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[11] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[11]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[12] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[12]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[12] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[12]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[13] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[13]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[13] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[13]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[14] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[14]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[14] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[14]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaDecoderLayer.forward[15] =========\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "<<<<<<< LlamaDecoderLayer.forward[15]\n",
      "hidden_states after input_layernorm shape torch.Size([1, 11, 2048])\n",
      "======== LlamaAttention.forward[15] =========\n",
      "bias False\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      "input_shape torch.Size([1, 11])\n",
      "hidden_shape (1, 11, -1, 64)\n",
      "query weight shape: torch.Size([2048, 2048])\n",
      "key weight shape: torch.Size([512, 2048])\n",
      "value weight shape: torch.Size([512, 2048])\n",
      "tmp torch.Size([1, 11, 2048])\n",
      "query_states torch.Size([1, 32, 11, 64])\n",
      "key_states torch.Size([1, 8, 11, 64])\n",
      "value_states torch.Size([1, 8, 11, 64])\n",
      "cos torch.Size([1, 11, 64])\n",
      "sin torch.Size([1, 11, 64])\n",
      "======== apply_rotary_pos_emb =========\n",
      "unsqueeze cos shape torch.Size([1, 1, 11, 64])\n",
      "unsqueeze sin shape torch.Size([1, 1, 11, 64])\n",
      "q_embed shape torch.Size([1, 32, 11, 64])\n",
      "k_embed shape torch.Size([1, 8, 11, 64])\n",
      ">>>>>>> LlamaDecoderLayer.forward[15]\n",
      "hidden_states after attn shape torch.Size([1, 11, 2048])\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n",
      ">>>>>>>> LlamaModel.forward\n",
      "======== LlamaRMSNorm.forward =========\n",
      "variance shape torch.Size([1, 11, 1])\n",
      "weghts shape torch.Size([2048])\n",
      "hidden_states shape torch.Size([1, 11, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 5.1046,  5.1268,  7.3774,  ..., -4.7377, -4.7379, -4.7383],\n",
       "         [11.7675, 12.5821, 10.6723,  ...,  0.8230,  0.8236,  0.8231],\n",
       "         [13.1911, 12.9374, 10.9242,  ..., -0.3592, -0.3591, -0.3589],\n",
       "         ...,\n",
       "         [12.0275, 10.4520, 10.9077,  ...,  0.8572,  0.8575,  0.8566],\n",
       "         [11.2537,  9.2107,  7.9047,  ..., -1.3219, -1.3206, -1.3209],\n",
       "         [10.4584,  8.6227,  9.6627,  ..., -1.7254, -1.7234, -1.7235]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6faa0b8f-327c-4bd3-a378-cab39298d0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 5.1046,  5.1268,  7.3774,  ..., -4.7377, -4.7379, -4.7383],\n",
       "         [11.7675, 12.5821, 10.6723,  ...,  0.8230,  0.8236,  0.8231],\n",
       "         [13.1911, 12.9374, 10.9242,  ..., -0.3592, -0.3591, -0.3589],\n",
       "         ...,\n",
       "         [12.0275, 10.4520, 10.9077,  ...,  0.8572,  0.8575,  0.8566],\n",
       "         [11.2537,  9.2107,  7.9047,  ..., -1.3219, -1.3206, -1.3209],\n",
       "         [10.4584,  8.6227,  9.6627,  ..., -1.7254, -1.7234, -1.7235]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
